<html>

<head>
  <title> cluster-delegator Documentation </title>
</head>

<body>

<center>
<h1> cluster-delegator 
<hr />

</h1>
</center>

<p> 
This is the documentation for the
cluster-delegator library by Shaun Harker. 8/23/11
</p>
<p>
contact: sharker@math.rutgers.edu 
</p>

<h2>(0) installation </h2>

<p>
Installation is not necessary as this is a header-only library. 
This is accomplished by defining every non-template function as "inline".
However, there are two dependencies: Boost and open-mpi. </p>

<p> Your best bet is to install Boost and open-mpi in /usr/local/. This puts everything in
a nice standard place, and one does not need to fuss as much to make sure headers and
libraries are found. Here are the relevant links for installation: </p>

<p>
<a href="http://www.open-mpi.org/faq/?category=building#easy-build"> 
instructions to build open-mpi 
</a>
</p>
<p>
<a href="http://www.boost.org/doc/libs/1_47_0/more/getting_started/unix-variants.html"> 
instructions to build boost 
</a>
</p>  

<p> Once Boost and open-mpi are installed, go ahead and obtain the software:
<pre> 
svn checkout http://cluster-delegator.googlecode.com/svn/trunk/ cluster-delegator
</pre>
Then type
<pre> 
     cd cluster-delegator
     cd example
     make clean
     make
     mpiexec -np 3 ./example1
</pre>
</p>
<p>


<h2>(1) target audience </h2>

<p>
The goal is to make it embarrassingly easy to write software utilizing
many processes to do embarrassingly parallel computation -- at least in C++.
</p>

<p>
The person who wants to use this software is a person who
<ul>
	<li> can write in C++ </li>
	<li> has a large computation involving many parallel, non-communicating tasks </li>
	<li> wants to have all the serialization and MPI details completely removed
  from their code for the sake of tidiness, simplicity, and ease of 
  debugging what really matters: their computation! </li>
</ul>
</p>

<h2>(2) getting oriented </h2>

<p>
The quickest way to learn how to use cluster-delegator
is to look at the examples 
<pre>
   ./examples/example1.cpp and 
   ./examples/example2.cpp
</pre>   
</p>

<p>
You should take a look at these and try to reason them out a little bit.
Many people will probably be quite close to understanding more or less
how the software works just by seeing these examples. (But don't worry,
we give an explanation below if it doesn't just click!)
</p>

<h2> (3) compiling and linking the examples  </h2>

<p>
To compile the examples, type (at the root of the distribution)
<pre>
cd examples
make clean
make
</pre>
</p>

<p>
Or, of course, one can issue the compilation and linking 
commands by hand. Here is how:
</p>
<pre>
cd examples
</pre>
<p>
Compile with:
</p>
<pre>
mpicxx -O3 -I../include/ -c -o example1.o example1.cpp
mpicxx -O3 -I../include/ -c -o example2.o example2.cpp
</pre>
<p>
Link with:
</p>
<pre>
mpicxx -lboost_serialization example1.o -o example1
mpicxx -lboost_serialization example2.o -o example2
</pre>

<h2> (4) running programs on a single machine  </h2>

<p>
To run the first example, type
<pre>
 mpiexec -np 8 ./example1
 </pre>
 
</p>

<p>
To run the second example, type
<pre>
 mpiexec -np 8 ./example2 42 is the answer
 </pre>
</p>

<p>
The number "8" is arbitrary; it's the number of processes you'd like. If you 
have a double core system, probably "3" is a good choice (one of the processes
will spend most of its time sleeping.) 
</p>

<h2> (5) running programs on a cluster  </h2>

<p>
Similar commands to the previous will probably work for clusters, though
you probably need more command line options. But likely, you will probably 
be required by system administrators to use their scheduling software. 
</p>

<p>
This is accomplished by writing a PBS script:
    an example is included <code> "./docs/script.sh" </code>
</p>

<p>
Here is what such a script looks like:
<pre>
---- script.sh --------
#!/bin/bash
#PBS -l nodes=10:ppn=8
cd $PBS_O_WORKDIR
mpiexec ./my_program
-----------------------
</pre>
</p>

<p>
In this simple example, we specified to use 10 nodes with 8 processors per
node.
</p>

<p>
To submit the program to the cluster, one would type
<pre>
ssh my_account@my.fancy.cluster.edu
# ... get it ready ...
qsub script.sh   #submit the job!
</pre>
</p>

<p>
You can periodically check the progress of your computation by typing
<pre>
qstat
</pre>
</p>

<p>
If something seems wrong, you can terminate your program with
<pre>
qdel 
</pre>
followed by your job number (which you can see from qstat)
</p>

<h2> (6) the simplest example  </h2>

<p>
The simplest program using the software is as follows:
</p>

<pre>
***** myprogram.cpp ************
#include "delegator/delegator.h"

class Process : public Coordinator_Worker_Process {};

int main ( int argc, char * argv [] ) {
    return delegator::Start < Process > (argc, argv); 
}
**************************
</pre>

<p>
This program creates no jobs, sends no jobs, works no jobs,
creates no results, and stores no results. But it does initialize
the delegator system. And it can easily be modified into a program
that DOES do something, by fleshing out class Process by providing
overrides of methods in Coordinator_Worker_Process.
</p>

<h2> (7) the Coordinator-Worker Scheme  </h2>

<p>
In order to actually make something happen, the user needs to
override methods from Coordinator_Worker_Process. To see how
this works, we'll describe the behavior of the algorithm called by
Start&ltProcess>(). This algorithm is called the Coordinator-Worker Scheme,
and is implemented by the class Coordinator_Worker_Scheme (which you don't
need to know). But you do need to know more or less how it works:
</p>

<ul>
<li> Of the N processes, N-1 are workers and 1 is a coordinator. </li>

<li> The coordinator is responsible for writing "jobs" and
reading "results". </li>

<li> The workers are responsible for accepting "jobs" and working them,
thus producing "results" </li>
</ul>

<p>
In step-by-step detail:
</p>

<ol>
	<li> One of the processes decides it is a coordinator, the
    others decide they are workers. The processes each
    execute the method
    <pre>
        void Process::command_line ( int argc, char * argv [] );
    </pre>
    to store/process the command line arguments. </li>
    
	<li> The coordinator process runs (one time only) the method  
		<pre>
        void Process::initialize ( void );
		</pre>
		
The next three things happen in an interspersed fashion, 
on demand as workers, jobs, and results become available:</li>

	<li> The coordinator process calls the method 
		<pre>
        int Process::write ( Message & job_message )
		</pre>

    in order to create "job_message" which is sent to a worker.</li>

	<li> A worker process calls the method 
    <pre>
        void Process::work ( Message & result_message, 
                             const Message & job_message ) const;
		</pre>

     on "job_message" received from the coordinator in order to
     produce "result_message" which is sent back to the coordinator.</li>

	<li> The coordinator process calls the method
    <pre>
        void Process::write ( constMessage & result_message )
		</pre>

    on the "result_message" which was received from a worker.</li>

	<li> The coordinator process runs (one time only) the method
		<pre>

        void Process::finalize ( void );
		</pre>
</li>
</ol>
<p>
Note that steps [3] [4] and [5] will happen many times and be interspersed,
but [1], [2], and [6] each happen only once and happen in the order 
they are listed.
</p>

<p> By the way, if these "Message" objects have got you confused, you can skip to 
section 13 (the last section) quickly to get the gist of them. </p>

<h2> (8) Coordinator_Worker_Process methods overview  </h2>

<p>
There are six methods which may be overridden in
Coordinator_Worker_Process. They are:
</p>

<dl>
<dt> command_line </dt>
<dd> set command line arguments so they are available to Process</dd>
<dt> initialize </dt>
<dd> prepare in some fashion for what is to come</dd>
<dt> write </dt>
<dd>   come up with a job to send to a worker and return 0
       OR realize there are no jobs left to send and return 1
       OR stall for results before producing a job and return 2  </dd> 
<dt> work </dt>
<dd> work a job and produce a result </dd>
<dt> read </dt>
<dd> accept a result and handle it in some way </dd>
<dt> finalize </dt>
<dd> finish up and do whatever is left to do </dd>
</dl>
<p>
Each of these methods has a default behavior, specified in the base
class Coordinator_Worker_Process. These functions are called by
the Coordinator_Worker_Scheme algorithm. Since a process is either
a coordinator or a worker, the methods divide up into the methods
called by the coordinator process, and the methods called by the
worker processes, and methods called by both.
</p>

<dl>
<dt> All processes: </dt>
<dd> command_line </dd>
<dt> Coordinator only: </dt>
<dd> initialize, write, read, finalize </dd>
<dt> Worker only: </dt>
<dd> work </dd>
</dl>

<p>
Only one of these processes has a return value, which is "write". It returns
0, 1, or 2, depending on the situation. For simple programs, it returns 0
while it is producing jobs, and then switches to returning 1 to indicate
there are no jobs left. More sophisticated programs might make use of the
2 option.
</p>

<h2> (9) Coordinator_Worker_Process member variables  </h2>

<p>
Coordinator_Worker_Process has several member variables, which are 
inherited by Process, and are used by default implementations of 
the methods.
</p>

<pre>
----- Command line arguments -----
(int argc;) and (char * * argv;)
</pre>

<p>
The default behavior of "command_line" is to set argc and argv to match
the command line parameters handed to main.
</p>

<pre>
----- The Message Stacks ------
std::stack&ltMessage&gt JOBS_TO_SEND; 
std::stack&ltMessage&gt RECEIVED_RESULTS;
</pre>

<p>
JOBS_TO_SEND is a stack which is intended to be populated by the user 
override of "initialize". The user would create jobs, make them into
job messages, and push them onto the JOBS_TO_SEND stack. The default
implementation of the "write" method pops a job message from
JOBS_TO_SEND and writes to its argument (which is then sent off to a
worker.)
</p>

<p>
RECEIVED_RESULTS is a stack which is automatically populated by the 
default implementation of "read". The default implementation of "read"
takes its argument (which is a result message received from some worker)
and pushes it onto the RECEIVED_RESULTS stack. The user can then write
an override for finalize in order to go through the RECEIVED_RESULTS
stack and handle the results however they wish.
</p>

<h2> (10) Coordinator_Worker_Process methods details </h2>

<p>
Here we describe the default behaviors of the methods of
Coordinator_Worker_Process. These behaviors have been discussed
already with respect to how they affect the member variables (in 
particular the message stacks), but we error on the side of
redundancy and give them again here.
</p>

<dl>

<dt> command_line: </dt>
<dd>  sets member variables argc and argv to match the passed parameters </dd>

<dt> initialize: </dt>
<dd>  does nothing </dd>

<dt> write:   (Read this part carefully.) </dt>
<dd>  checks if there is an item on member variable
	<pre>
      std::stack&ltMessage&gt JOBS_TO_SEND
  </pre>
  if so, it pops that item from the stack and writes it to 
  job_message and returns code 0, which means "i produced a job."
  Otherwise, it returns code 1, which means "no jobs left to produce"
  It NEVER returns code 2, which would mean "I am waiting on information
                                 before I can produce more jobs" </dd>

<dt> work: </dt>
<dd>  does nothing </dd>

<dt> read: </dt>
<dd> pushes the message "result_message" onto the member variable 
	<pre>
       std::stack&ltMessage&gt RECEIVED_RESULTS
	</pre> </dd>
<dt> finalize: </dt>
<dd>  does nothing. </dd>
</dl>

<p>
The easiest way to use the software is to only override
initialize, work, and finalize.
</p>

<h2> (11) example1: override just initialize, work, and finalize </h2>

<p>
The easiest way to use the software is to only override
initialize, work, and finalize. This is what is done in
<pre>
   ./examples/example1.cpp
</pre>
</p>

<p>
Then we will have
<dl>
<dt> initialize: </dt>
<dd>   invent jobs, turn them into job_messages, and push them onto 
   the member variable
   <pre>
      std::stack&ltMessage&gt JOBS_TO_SEND
</pre> </dd>
<dt> finalize: </dt>
<dd>   read the result_messages off the member variable
<pre>
       std::stack&ltMessage&gt RECEIVED_RESULTS
       </pre>
   and extract the results and deal with them as necessary. </dd>
<dt> work:  </dt>
<dd> extract the job from job_message,
   do a computation on the job to produce a result,
   create result_message from the result </dd>
</dl>
   
</p>

<h2> (12) example2: override everything </h2>

<p>
One does not have to use the default behavior of write and read 
and may override them not to use the JOBS_TO_SEND and RECEIVED_RESULTS 
stacks at all. 
</p>

<p>
By overriding all the methods, one has a considerable degree of control, 
and can even arrange to wait until certain results have arrived before
determining what the next jobs should be. The function "write" can
report a return value of 2 if it wishes to indicate it is in this
"waiting for more results to be dealt with by 'read' before I can
create a new job". This allows "write" to not produce a job_message,
but not cause the distributed computing scheme to believe there
are no jobs left and start retiring free workers.
</p>

<h2> (13) jobs, results, and messages</h2>

<p>
What is a job? Anything you like. What is a result? Anything you like.
But in order for the software to work, your jobs and results must be
communicated in some uniform manner. This is where class Message comes in:
it is a convenient class you can use to "serialize" your data so it can
be passed around by the processes.
</p>

<p>
class Message is really just a wrapper around the Boost serialization package.
The semantics of Message are quite easy:
</p>

example:
<pre>
Message job_message;  // now I have an empty message
int jobdata1; 
char jobdata2; 
std::vector &lt int &gt jobdata3; 
std::unordered_map &lt int, float &gt jobdata4;
std::string jobdata5;
// code to produce data in jobdata variables
job_message &lt&lt jobdata1;
job_message &lt&lt jobdata2;
job_message &lt&lt jobdata3;
job_message &lt&lt jobdata4;
</pre>

<p>
Later, this data may be extracted in precisely the same way, except 
we replace the &lt&lt operators with &gt&gt operators. And you must extract
the data in the same order it was inserted! (Not the reverse order, for
example, or in a random order)
</p>

<p>
See the included examples, and you should be able to sort it out! 
Good luck, and have fun.
</p>

</body>
</html>
